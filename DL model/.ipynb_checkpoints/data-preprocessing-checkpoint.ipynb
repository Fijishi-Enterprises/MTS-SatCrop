{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset from kaggle and unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d bhavesh907/crop-classificationcs2292017usgscroplanddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip crop-classificationcs2292017usgscroplanddata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDAL's version is: 3.0.4\n",
      "<module 'osgeo.gdal' from '/home/monster/anaconda3/envs/geo_py37/lib/python3.7/site-packages/osgeo/gdal.py'>\n",
      "Class 0 contains 6048 pixels\n",
      "Class 1 contains 51120 pixels\n",
      "Class 2 contains 70704 pixels\n",
      "Class 4 contains 3492 pixels\n",
      "Class 21 contains 47700 pixels\n",
      "Class 23 contains 864 pixels\n",
      "Class 24 contains 494748 pixels\n",
      "Class 28 contains 73512 pixels\n",
      "Class 33 contains 6120 pixels\n",
      "Class 36 contains 1543068 pixels\n",
      "Class 37 contains 23724 pixels\n",
      "Class 42 contains 936 pixels\n",
      "Class 48 contains 612 pixels\n",
      "Class 49 contains 37476 pixels\n",
      "Class 54 contains 15696 pixels\n",
      "Class 57 contains 144 pixels\n",
      "Class 59 contains 2124 pixels\n",
      "Class 61 contains 379464 pixels\n",
      "Class 66 contains 13464 pixels\n",
      "Class 67 contains 8208 pixels\n",
      "Class 69 contains 8311968 pixels\n",
      "Class 71 contains 4644 pixels\n",
      "Class 72 contains 144 pixels\n",
      "Class 75 contains 4729104 pixels\n",
      "Class 76 contains 340560 pixels\n",
      "Class 77 contains 1620 pixels\n",
      "Class 111 contains 148788 pixels\n",
      "Class 121 contains 766044 pixels\n",
      "Class 122 contains 331164 pixels\n",
      "Class 123 contains 138420 pixels\n",
      "Class 124 contains 31998 pixels\n",
      "Class 131 contains 37512 pixels\n",
      "Class 152 contains 1080 pixels\n",
      "Class 176 contains 225396 pixels\n",
      "Class 190 contains 5904 pixels\n",
      "Class 195 contains 7164 pixels\n",
      "Class 204 contains 410688 pixels\n",
      "Class 205 contains 8640 pixels\n",
      "Class 206 contains 16020 pixels\n",
      "Class 208 contains 2124 pixels\n",
      "Class 209 contains 648 pixels\n",
      "Class 212 contains 1404 pixels\n",
      "Class 213 contains 720 pixels\n",
      "Class 216 contains 756 pixels\n",
      "Class 217 contains 23004 pixels\n",
      "Class 218 contains 2160 pixels\n",
      "Class 220 contains 3420 pixels\n",
      "Class 224 contains 36 pixels\n",
      "Class 225 contains 617040 pixels\n",
      "Class 226 contains 72 pixels\n",
      "Class 227 contains 2448 pixels\n",
      "Class 236 contains 62424 pixels\n",
      "Class 237 contains 14292 pixels\n",
      "Class 238 contains 4716 pixels\n",
      "Class 242 contains 252 pixels\n",
      "Class 255 contains 9381144 pixels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from osgeo import gdal, gdal_array\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "roi_ds = gdal.Open('/media/monster/New Volume3/neurafarms/downloaded_sat_images/rose_mlready/cdl2017.tiff', gdal.GA_ReadOnly)\n",
    "\n",
    "#train_ds = gdal.Open('D:/neurafarms/downloaded_sat_images/rose_mlready/0306.tiff', gdal.GA_ReadOnly)\n",
    "\n",
    "roi = roi_ds.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "# How many pixels are in each class?\n",
    "classes = np.unique(roi)\n",
    "# Iterate over all class labels in the ROI image, printing out some information\n",
    "for c in classes:\n",
    "    print('Class {c} contains {n} pixels'.format(c=c,\n",
    "                                                 n=(roi == c).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   4,  21,  23,  24,  28,  33,  36,  37,  42,  48,\n",
       "        49,  54,  57,  59,  61,  66,  67,  69,  71,  72,  75,  76,  77,\n",
       "       111, 121, 122, 123, 124, 131, 152, 176, 190, 195, 204, 205, 206,\n",
       "       208, 209, 212, 213, 216, 217, 218, 220, 224, 225, 226, 227, 236,\n",
       "       237, 238, 242, 255], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {}\n",
    "for c in classes:\n",
    "    dict[c] = (roi == c).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6048,\n",
       " 1: 51120,\n",
       " 2: 70704,\n",
       " 4: 3492,\n",
       " 21: 47700,\n",
       " 23: 864,\n",
       " 24: 494748,\n",
       " 28: 73512,\n",
       " 33: 6120,\n",
       " 36: 1543068,\n",
       " 37: 23724,\n",
       " 42: 936,\n",
       " 48: 612,\n",
       " 49: 37476,\n",
       " 54: 15696,\n",
       " 57: 144,\n",
       " 59: 2124,\n",
       " 61: 379464,\n",
       " 66: 13464,\n",
       " 67: 8208,\n",
       " 69: 8311968,\n",
       " 71: 4644,\n",
       " 72: 144,\n",
       " 75: 4729104,\n",
       " 76: 340560,\n",
       " 77: 1620,\n",
       " 111: 148788,\n",
       " 121: 766044,\n",
       " 122: 331164,\n",
       " 123: 138420,\n",
       " 124: 31998,\n",
       " 131: 37512,\n",
       " 152: 1080,\n",
       " 176: 225396,\n",
       " 190: 5904,\n",
       " 195: 7164,\n",
       " 204: 410688,\n",
       " 205: 8640,\n",
       " 206: 16020,\n",
       " 208: 2124,\n",
       " 209: 648,\n",
       " 212: 1404,\n",
       " 213: 720,\n",
       " 216: 756,\n",
       " 217: 23004,\n",
       " 218: 2160,\n",
       " 220: 3420,\n",
       " 224: 36,\n",
       " 225: 617040,\n",
       " 226: 72,\n",
       " 227: 2448,\n",
       " 236: 62424,\n",
       " 237: 14292,\n",
       " 238: 4716,\n",
       " 242: 252,\n",
       " 255: 9381144}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_x = sorted(dict.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(224, 36),\n",
       " (226, 72),\n",
       " (57, 144),\n",
       " (72, 144),\n",
       " (242, 252),\n",
       " (48, 612),\n",
       " (209, 648),\n",
       " (213, 720),\n",
       " (216, 756),\n",
       " (23, 864),\n",
       " (42, 936),\n",
       " (152, 1080),\n",
       " (212, 1404),\n",
       " (77, 1620),\n",
       " (59, 2124),\n",
       " (208, 2124),\n",
       " (218, 2160),\n",
       " (227, 2448),\n",
       " (220, 3420),\n",
       " (4, 3492),\n",
       " (71, 4644),\n",
       " (238, 4716),\n",
       " (190, 5904),\n",
       " (0, 6048),\n",
       " (33, 6120),\n",
       " (195, 7164),\n",
       " (67, 8208),\n",
       " (205, 8640),\n",
       " (66, 13464),\n",
       " (237, 14292),\n",
       " (54, 15696),\n",
       " (206, 16020),\n",
       " (217, 23004),\n",
       " (37, 23724),\n",
       " (124, 31998),\n",
       " (49, 37476),\n",
       " (131, 37512),\n",
       " (21, 47700),\n",
       " (1, 51120),\n",
       " (236, 62424),\n",
       " (2, 70704),\n",
       " (28, 73512),\n",
       " (123, 138420),\n",
       " (111, 148788),\n",
       " (176, 225396),\n",
       " (122, 331164),\n",
       " (76, 340560),\n",
       " (61, 379464),\n",
       " (204, 410688),\n",
       " (24, 494748),\n",
       " (225, 617040),\n",
       " (121, 766044),\n",
       " (36, 1543068),\n",
       " (75, 4729104),\n",
       " (69, 8311968),\n",
       " (255, 9381144)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes = [69,75,36,121,225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_b1 = np.zeros((train_ds.RasterYSize, train_ds.RasterXSize, train_ds.RasterCount),\n",
    "#               gdal_array.GDALTypeCodeToNumericTypeCode(train_ds.GetRasterBand(1).DataType))\n",
    "#for b in range(img_b1.shape[2]):\n",
    "#    img_b1[:, :, b] = train_ds.GetRasterBand(b + 1).ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_b1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many non-zero entries we have -- i.e. how many training data samples?\n",
    "n_samples = (roi > 0).sum()\n",
    "print('We have {n} samples'.format(n=n_samples))\n",
    "\n",
    "# What are our classification labels?\n",
    "labels = np.unique(roi[roi > 0])\n",
    "print('The training data include {n} classes: {classes}'.format(n=labels.size, \n",
    "                                                                classes=labels))\n",
    "# We will need a \"X\" matrix containing our features, and a \"y\" array containing our labels\n",
    "#     These will have n_samples rows\n",
    "#     In other languages we would need to allocate these and them loop to fill them, but NumPy can be faster\n",
    "\n",
    "#X = img_b1[roi > 0, :]  # include 8th band, which is Fmask, for now\n",
    "y = roi[roi > 0]\n",
    "\n",
    "#print('Our X matrix is sized: {sz}'.format(sz=X.shape))\n",
    "print('Our y array is sized: {sz}'.format(sz=y.shape))\n",
    "\n",
    "# Mask out clouds, cloud shadows, and snow using Fmask\n",
    "#clear = X[:, 7] <= 1\n",
    "\n",
    "#X = X[clear, :7]  # we can ditch the Fmask band now\n",
    "#y = y[clear]\n",
    "\n",
    "#print('After masking, our X matrix is sized: {sz}'.format(sz=X.shape))\n",
    "print('After masking, our y array is sized: {sz}'.format(sz=y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = img_b1[roi==classes, :]  # include 8th band, which is Fmask, for now 69,75,36,121,225\n",
    "y_class_69 = roi[roi==69]\n",
    "y_class_75 = roi[roi==75]\n",
    "y_class_36 = roi[roi==36]\n",
    "y_class_121 = roi[roi==121]\n",
    "y_class_225 = roi[roi==225]\n",
    "\n",
    "\n",
    "# Find how many non-zero entries we have -- i.e. how many training data samples?\n",
    "for top in top_classes:\n",
    "    n_samples = (roi==top).sum()\n",
    "    print('We have {n} samples for the class {top}'.format(n=n_samples,top = top))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "images = ['/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/0306.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20170410.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20170601.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20170615.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20170708.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20170807.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20170905.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20170923.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20171015.tiff',\n",
    "          '/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/20171207.tiff']\n",
    "print(len(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = roi==69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a),len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(a),len(y_class_69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#69,75,36,121,225\n",
    "print(\"Reading class 69\")\n",
    "X_class_69 = pd.DataFrame()\n",
    "\n",
    "for img in images:\n",
    "    print(img)\n",
    "    train_ds = gdal.Open(img, gdal.GA_ReadOnly)\n",
    "    \n",
    "    print(train_ds.RasterXSize,train_ds.RasterYSize)\n",
    "\n",
    "    img_b1 = np.zeros((train_ds.RasterYSize, train_ds.RasterXSize, train_ds.RasterCount),\n",
    "                   gdal_array.GDALTypeCodeToNumericTypeCode(train_ds.GetRasterBand(1).DataType))\n",
    "    for b in range(img_b1.shape[2]):\n",
    "        img_b1[:, :, b] = train_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    print(img_b1.shape)\n",
    "    \n",
    "    Xt = img_b1[roi==69, :] \n",
    "    Xt1 = pd.DataFrame(Xt)\n",
    "    X_class_69 = pd.concat([Xt1,X_class_69],axis=1)\n",
    "    gc.collect()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_b1[a,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = img_b1[roi > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =X[y==69,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[d==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#69,75,36,121,225\n",
    "print(\"Reading class 69\")\n",
    "X_class_69 = pd.DataFrame()\n",
    "\n",
    "for img in images:\n",
    "    print(img)\n",
    "    train_ds = gdal.Open(img, gdal.GA_ReadOnly)\n",
    "    \n",
    "    print(train_ds.RasterXSize,train_ds.RasterYSize)\n",
    "\n",
    "    img_b1 = np.zeros((train_ds.RasterYSize, train_ds.RasterXSize, train_ds.RasterCount),\n",
    "                   gdal_array.GDALTypeCodeToNumericTypeCode(train_ds.GetRasterBand(1).DataType))\n",
    "    for b in range(img_b1.shape[2]):\n",
    "        img_b1[:, :, b] = train_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    print(img_b1.shape)\n",
    "    \n",
    "    Xt = img_b1[roi==69, :] \n",
    "    Xt1 = pd.DataFrame(Xt)\n",
    "    X_class_69 = pd.concat([Xt1,X_class_69],axis=1)\n",
    "    gc.collect()\n",
    "    \n",
    "print(\"-----------------------------\")\n",
    "print(\"Reading class 75\")\n",
    "\n",
    "X_class_75 = pd.DataFrame()\n",
    "\n",
    "for img in images:\n",
    "    print(img)\n",
    "    train_ds = gdal.Open(img, gdal.GA_ReadOnly)\n",
    "    \n",
    "    print(train_ds.RasterXSize,train_ds.RasterYSize)\n",
    "\n",
    "    img_b1 = np.zeros((train_ds.RasterYSize, train_ds.RasterXSize, train_ds.RasterCount),\n",
    "                   gdal_array.GDALTypeCodeToNumericTypeCode(train_ds.GetRasterBand(1).DataType))\n",
    "    for b in range(img_b1.shape[2]):\n",
    "        img_b1[:, :, b] = train_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    print(img_b1.shape)\n",
    "    \n",
    "    Xt = img_b1[roi==75, :]\n",
    "    Xt1 = pd.DataFrame(Xt)\n",
    "    X_class_75 = pd.concat([Xt1,X_class_75],axis=1)\n",
    "    gc.collect()\n",
    "    \n",
    "print(\"-----------------------------\")\n",
    "print(\"Reading class 36\")\n",
    "\n",
    "X_class_36 = pd.DataFrame()\n",
    "\n",
    "for img in images:\n",
    "    print(img)\n",
    "    train_ds = gdal.Open(img, gdal.GA_ReadOnly)\n",
    "    \n",
    "    print(train_ds.RasterXSize,train_ds.RasterYSize)\n",
    "\n",
    "    img_b1 = np.zeros((train_ds.RasterYSize, train_ds.RasterXSize, train_ds.RasterCount),\n",
    "                   gdal_array.GDALTypeCodeToNumericTypeCode(train_ds.GetRasterBand(1).DataType))\n",
    "    for b in range(img_b1.shape[2]):\n",
    "        img_b1[:, :, b] = train_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    print(img_b1.shape)\n",
    "    \n",
    "    Xt = img_b1[roi==36, :]\n",
    "    Xt1 = pd.DataFrame(Xt)\n",
    "    X_class_36 = pd.concat([Xt1,X_class_36],axis=1)\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "print(\"-----------------------------\")\n",
    "print(\"Reading class 121\")\n",
    "\n",
    "X_class_121 = pd.DataFrame()\n",
    "\n",
    "for img in images:\n",
    "    print(img)\n",
    "    train_ds = gdal.Open(img, gdal.GA_ReadOnly)\n",
    "    \n",
    "    print(train_ds.RasterXSize,train_ds.RasterYSize)\n",
    "\n",
    "    img_b1 = np.zeros((train_ds.RasterYSize, train_ds.RasterXSize, train_ds.RasterCount),\n",
    "                   gdal_array.GDALTypeCodeToNumericTypeCode(train_ds.GetRasterBand(1).DataType))\n",
    "    for b in range(img_b1.shape[2]):\n",
    "        img_b1[:, :, b] = train_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    print(img_b1.shape)\n",
    "    \n",
    "    Xt = img_b1[roi==121, :]\n",
    "    Xt1 = pd.DataFrame(Xt)\n",
    "    X_class_121 = pd.concat([Xt1,X_class_121],axis=1)\n",
    "    gc.collect()   \n",
    "    \n",
    "print(\"-----------------------------\")\n",
    "print(\"Reading class 225\")\n",
    "\n",
    "X_class_225 = pd.DataFrame()\n",
    "\n",
    "for img in images:\n",
    "    print(img)\n",
    "    train_ds = gdal.Open(img, gdal.GA_ReadOnly)\n",
    "    \n",
    "    print(train_ds.RasterXSize,train_ds.RasterYSize)\n",
    "\n",
    "    img_b1 = np.zeros((train_ds.RasterYSize, train_ds.RasterXSize, train_ds.RasterCount),\n",
    "                   gdal_array.GDALTypeCodeToNumericTypeCode(train_ds.GetRasterBand(1).DataType))\n",
    "    for b in range(img_b1.shape[2]):\n",
    "        img_b1[:, :, b] = train_ds.GetRasterBand(b + 1).ReadAsArray()\n",
    "    print(img_b1.shape)\n",
    "    \n",
    "    Xt = img_b1[roi==225, :]\n",
    "    Xt1 = pd.DataFrame(Xt)\n",
    "    X_class_225 = pd.concat([Xt1,X_class_225],axis=1)\n",
    "    gc.collect()\n",
    "\n",
    "print(\"-----------------------------\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_class_69.shape,y_class_69.shape)\n",
    "print(X_class_75.shape,y_class_75.shape)\n",
    "print(X_class_36.shape,y_class_36.shape)\n",
    "print(X_class_121.shape,y_class_121.shape)\n",
    "print(X_class_225.shape,y_class_225.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class_69_sampled = X_class_69.sample(n=100000)\n",
    "X_class_75_sampled = X_class_75.sample(n=100000)\n",
    "X_class_36_sampled = X_class_36.sample(n=100000)\n",
    "X_class_121_sampled = X_class_121.sample(n=100000)\n",
    "X_class_225_sampled = X_class_225.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class_69_sampled = y_class_69[X_class_69_sampled.index]\n",
    "y_class_75_sampled = y_class_75[X_class_75_sampled.index]\n",
    "y_class_36_sampled = y_class_36[X_class_36_sampled.index]\n",
    "y_class_121_sampled = y_class_121[X_class_121_sampled.index]\n",
    "y_class_225_sampled = y_class_225[X_class_225_sampled.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class_69_sampled.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/x_final',X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.load('/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/x_final.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa = xx['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pd.DataFrame(y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.reset_index(inplace=True, drop=True)\n",
    "\n",
    "q = pd.concat([X_final,ss],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('/media/monster/New Volume/neurafarms/downloaded_sat_images/rose_mlready/final_df',q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.columns = ['col_'+str(i) for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.DataFrame()\n",
    "\n",
    "X_final = X_final.append([X_class_69_sampled,X_class_75_sampled,X_class_36_sampled,X_class_121_sampled,X_class_225_sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final = np.append(y_class_69_sampled,[y_class_75_sampled,y_class_36_sampled,y_class_121_sampled,y_class_225_sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class_69_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_model_input.npy')\n",
    "y_train = np.load('y_model_input.npy')\n",
    "\n",
    "X_final = np.load('X_final.npy')\n",
    "y_final = np.load('y_final.npy')\n",
    "y_final_onehot = np.load('y_final_onehot.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_final)\n",
    "encoded_Y = encoder.transform(y_final)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = keras.utils.to_categorical(encoded_Y,num_classes=5) #np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(dummy_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dummy_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_final[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_final, dummy_y, test_size=0.05, random_state=42,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(X_final)\n",
    "b = pd.DataFrame(y_final)\n",
    "\n",
    "C = pd.concat([a,b],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape,a.shape,b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.columns = ['col_'+str(i) for i in range(51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = [i*5 for i in list(range(11))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_df = pd.DataFrame(pd.Series(C.iloc[:,-1]))\n",
    "i= 0\n",
    "for m in mul[:-1]:\n",
    "    print(\"printing for t_\",i)\n",
    "    print(a.iloc[:,0+m:5+m].head(5))\n",
    "    temp = a.iloc[:,0+m:5+m]\n",
    "    ndvi = (temp.loc[:,temp.columns[0]] - temp.loc[:,temp.columns[4]]) / (temp.loc[:,temp.columns[4]] + temp.loc[:,temp.columns[0]])\n",
    "    Xt1 = pd.DataFrame(ndvi)\n",
    "    Xt1.columns = [\"t_\"+str(i)]\n",
    "    ndvi_df = pd.concat([Xt1,ndvi_df],axis=1)\n",
    "    print(ndvi_df.shape)\n",
    "    print(\"------------------------------\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = pd.DataFrame(np.mean(ndvi_df.loc[ndvi_df['col_50']==69,['t_9', 't_8', 't_7', 't_6', 't_5', 't_4', 't_3', 't_2', 't_1', 't_0']],axis=0))\n",
    "c2 = pd.DataFrame(np.mean(ndvi_df.loc[ndvi_df['col_50']==75,['t_9', 't_8', 't_7', 't_6', 't_5', 't_4', 't_3', 't_2', 't_1', 't_0']],axis=0))\n",
    "c3 = pd.DataFrame(np.mean(ndvi_df.loc[ndvi_df['col_50']==121,['t_9', 't_8', 't_7', 't_6', 't_5', 't_4', 't_3', 't_2', 't_1', 't_0']],axis=0))\n",
    "c4 = pd.DataFrame(np.mean(ndvi_df.loc[ndvi_df['col_50']==225,['t_9', 't_8', 't_7', 't_6', 't_5', 't_4', 't_3', 't_2', 't_1', 't_0']],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(c1.index,c1.iloc[:,0],color='r')\n",
    "plt.plot(c2.index,c2.iloc[:,0],color='g')\n",
    "plt.plot(c3.index,c3.iloc[:,0],color='b')\n",
    "plt.plot(c4.index,c4.iloc[:,0],color='y')\n",
    "\n",
    "ndvi_df['avg_ndvi'] = np.mean(ndvi_df,axis=1)\n",
    "\n",
    "pd.pivot_table(ndvi_df,index=[\"col_50\"],values = ['avg_ndvi'] ,aggfunc=np.mean)\n",
    "\n",
    "ndvi_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.expand_dims(y_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = np.expand_dims(y_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(200, input_shape=(50, ), activation='relu',kernel_regularizer=regularizers.l2(1e-5),kernel_initializer=keras.initializers.glorot_normal(seed=seed),bias_initializer='zeros'))\n",
    "model.add(Dropout(5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrc(y_true, y_pred):\n",
    "    keras.backend.categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
    "\n",
    "sgd = keras.optimizers.Adadelta()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          epochs=100,\n",
    "          batch_size=100,\n",
    "         shuffle=True)\n",
    "score = model.evaluate(X_test, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "\n",
    "model1 = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model1.add(Dense(200, activation='relu', input_shape=(50,)))\n",
    "print(model1.input_shape)\n",
    "print(model1.output_shape)\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(n_classes, activation='sigmoid'))\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model1.fit(X_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model1.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(kernel_size = 5, strides=1,filters = 32, activation='relu',input_shape=(50,1)))\n",
    "                    \n",
    "print(model.input_shape)\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(MaxPooling1D(pool_size = (2), strides=(2)))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv1D (kernel_size = 5, strides=1, filters = 64, activation='relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(MaxPooling1D(pool_size = (2), strides=(2)))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dense (1000, activation='relu'))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Dense(n_classes, activation = 'softmax'))#,activity_regularizer=keras.regularizers.l2()))\n",
    "print(model.output_shape)\n",
    "\n",
    "#model.compile( loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.01), metrics=[keras.metrics.categorical_accuracy])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X1, y_train, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X2, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize our model with 500 trees\n",
    "rf = RandomForestClassifier(n_estimators=5, oob_score=True)\n",
    "\n",
    "# Fit our model to training data\n",
    "rf = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our OOB prediction of accuracy is: {oob}%'.format(oob=rf.oob_score_ * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = [1, 2, 3, 4, 5]\n",
    "\n",
    "for b, imp in zip(bands, rf.feature_importances_):\n",
    "    print('Band {b} importance: {imp}'.format(b=b, imp=imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train = pd.DataFrame(X_train)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#model6 = GaussianNB()\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#model6 = SVC(kernel = 'linear', random_state = 0)\n",
    "\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#model6 = KNeighborsClassifier(n_neighbors = 15, metric = 'minkowski', p = 2)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model6 = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#model6 = XGBClassifier(learning_rate =0.1,n_estimators=9,max_depth=6,min_child_weight=2,gamma=0,subsample=0.7,\n",
    "# colsample_bytree=0.7, reg_alpha=0.05, objective= 'multi:softmax', nthread=4,scale_pos_weight=1,seed=27)\n",
    "\n",
    "\n",
    "model6.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model6.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
